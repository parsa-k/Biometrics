{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p3r7V0jBu5L"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TvjbRdtnBx69"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGJwtk3zBcET",
        "outputId": "ed53573d-79af-4c2b-a276-15faabe1e2cd"
      },
      "outputs": [],
      "source": [
        "# Download dataset\n",
        "\n",
        "\n",
        "images_dir = os.path.join(\"./data/img_align_celeba\")\n",
        "attributes_file = os.path.join(\"./data/list_attr_celeba.csv\")\n",
        "land_mark = os.path.join(\"./data/list_landmarks_align_celeba.csv\")\n",
        "face_box = os.path.join(\"./data/list_bbox_celeba.csv\")\n",
        "partition = os.path.join(\"./data/list_eval_partition.csv\")\n",
        "\n",
        "obj = 20\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrdYx8sawKvz",
        "outputId": "9734c058-068d-41d4-c8fb-062b69c279ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\parsak\\AppData\\Local\\Temp\\ipykernel_21512\\2217787362.py:4: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  image_labels = pd.read_csv(file_path, delim_whitespace=True, header=None, names=[\"image_name\", \"label\"])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of valid labels: 2343\n",
            "   image_name  label\n",
            "0  000001.jpg   2880\n",
            "1  000002.jpg   2937\n",
            "2  000003.jpg   8692\n",
            "3  000004.jpg   5805\n",
            "5  000006.jpg   4153\n",
            "Filtered labels saved to ./filtered_identity_CelebA.txt\n"
          ]
        }
      ],
      "source": [
        "file_path = \"./data/identity_CelebA.txt\"\n",
        "\n",
        "# Load image labels into a DataFrame\n",
        "image_labels = pd.read_csv(file_path, delim_whitespace=True, header=None, names=[\"image_name\", \"label\"])\n",
        "\n",
        "# Count the number of images per label\n",
        "label_counts = image_labels[\"label\"].value_counts()\n",
        "\n",
        "# Filter labels with at least 29 images\n",
        "valid_labels = label_counts[label_counts == 30].index\n",
        "\n",
        "# Filter the DataFrame to keep only valid labels\n",
        "filtered_image_labels = image_labels[image_labels[\"label\"].isin(valid_labels)]\n",
        "\n",
        "# Example usage: Print the number of valid labels and a preview of the filtered DataFrame\n",
        "print(f\"Number of valid labels: {len(valid_labels)}\")\n",
        "print(filtered_image_labels.head())\n",
        "\n",
        "# Optional: Save the filtered DataFrame to a new file if needed\n",
        "filtered_file_path = \"./filtered_identity_CelebA.txt\"\n",
        "filtered_image_labels.to_csv(filtered_file_path, index=False, header=False, sep=\" \")\n",
        "print(f\"Filtered labels saved to {filtered_file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTmNMlVl65x_",
        "outputId": "fced8eb7-e009-4b7a-f840-3db4a110df4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     image_name  label\n",
            "31   000059.jpg      5\n",
            "47   000105.jpg      9\n",
            "170  000457.jpg     11\n",
            "180  000485.jpg     13\n",
            "226  000622.jpg      1\n",
            "500 selected labels and images saved to ./selected_500_labels_images_renamed.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\parsak\\AppData\\Local\\Temp\\ipykernel_21512\\768325506.py:6: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  filtered_image_labels = pd.read_csv(\"./filtered_identity_CelebA.txt\", delim_whitespace=True, header=None, names=[\"image_name\", \"label\"])\n",
            "C:\\Users\\parsak\\AppData\\Local\\Temp\\ipykernel_21512\\768325506.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected_images[\"label\"] = selected_images[\"label\"].map(label_mapping)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Load the filtered labels DataFrame (from the previous step)\n",
        "filtered_image_labels = pd.read_csv(\"./filtered_identity_CelebA.txt\", delim_whitespace=True, header=None, names=[\"image_name\", \"label\"])\n",
        "\n",
        "# Extract the unique labels from the filtered data\n",
        "unique_labels = filtered_image_labels[\"label\"].unique()\n",
        "\n",
        "# Randomly select 500 labels from the unique labels\n",
        "selected_labels = random.sample(list(unique_labels), obj)\n",
        "\n",
        "# Create a mapping from the original labels to new labels (0 to 499)\n",
        "label_mapping = {original_label: new_label for new_label, original_label in enumerate(selected_labels, start=0)}\n",
        "\n",
        "# Filter the dataset to include only images from the selected labels\n",
        "selected_images = filtered_image_labels[filtered_image_labels[\"label\"].isin(selected_labels)]\n",
        "\n",
        "# Replace the original labels with the new labels in the filtered dataset\n",
        "selected_images[\"label\"] = selected_images[\"label\"].map(label_mapping)\n",
        "\n",
        "# Example: Print the first 5 rows of the updated DataFrame\n",
        "print(selected_images.head())\n",
        "\n",
        "# Optionally, save the updated DataFrame to a new file\n",
        "selected_images_file = \"./selected_500_labels_images_renamed.txt\"\n",
        "selected_images.to_csv(selected_images_file, index=False, header=False, sep=\" \")\n",
        "print(f\"500 selected labels and images saved to {selected_images_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_AZsbcjc7cv",
        "outputId": "947073c1-ced0-4637-886a-0b84bc3cf7c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train DataLoader: 4 batches\n",
            "Validation DataLoader: 1 batches\n",
            "Test DataLoader: 1 batches\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the image preprocessing transform (resize, normalization)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to match ResNet18 input size\n",
        "    transforms.ToTensor(),  # Convert image to Tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize as per ImageNet stats\n",
        "])\n",
        "\n",
        "# Custom dataset class\n",
        "class CelebADataset(Dataset):\n",
        "    def __init__(self, image_labels_df, images_dir, transform=None):\n",
        "        self.image_labels_df = image_labels_df\n",
        "        self.images_dir = images_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_labels_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the image path and label\n",
        "        image_name = self.image_labels_df.iloc[idx, 0]\n",
        "        label = self.image_labels_df.iloc[idx, 1]\n",
        "\n",
        "        # Open the image\n",
        "        image_path = f\"{self.images_dir}/{image_name}\"\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Split the selected_images into train, validation, and test sets directly\n",
        "train_data, temp_data = train_test_split(\n",
        "    selected_images,\n",
        "    train_size=0.8,\n",
        "    stratify=selected_images[\"label\"]\n",
        ")\n",
        "valid_data, test_data = train_test_split(\n",
        "    temp_data,\n",
        "    train_size=0.5,  # Split the remaining 20% equally\n",
        "    stratify=temp_data[\"label\"]\n",
        ")\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = CelebADataset(train_data, images_dir, transform=transform)\n",
        "valid_dataset = CelebADataset(valid_data, images_dir, transform=transform)\n",
        "test_dataset = CelebADataset(test_data, images_dir, transform=transform)\n",
        "\n",
        "# Create DataLoaders\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Example: Print the number of batches for each DataLoader\n",
        "print(f\"Train DataLoader: {len(train_loader)} batches\")\n",
        "print(f\"Validation DataLoader: {len(valid_loader)} batches\")\n",
        "print(f\"Test DataLoader: {len(test_loader)} batches\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vl7YDNQ1_QE",
        "outputId": "5a007aa5-b874-4ed5-8c80-c74c8bd7c8a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images shape: torch.Size([128, 3, 224, 224])\n",
            "Labels shape: torch.Size([128])\n",
            "tensor([16,  4,  1, 19, 15,  2, 15,  6,  4,  6, 19,  5, 17,  5,  5, 11,  9, 11,\n",
            "         7,  0,  7, 15, 18,  2, 18, 18,  6,  9,  6, 14, 11, 12, 13, 10,  9,  5,\n",
            "         6, 16,  1, 15, 12, 17,  2, 18, 12,  2,  7,  0, 11, 10,  8,  6,  8,  4,\n",
            "        18, 11, 10,  3, 13, 11,  8, 19, 15, 12,  4, 12, 19, 12,  3, 15,  8,  5,\n",
            "         6,  6,  5, 17, 14, 16,  2, 18,  7,  2, 15,  7,  5,  4, 19,  8,  1,  9,\n",
            "         9,  2,  5, 15,  0,  7,  4, 12, 11, 11,  9, 19,  7,  7,  2,  9, 17, 14,\n",
            "        17,  2, 18, 10, 11,  5,  9,  0, 13, 18, 19, 11, 19, 10, 10, 16, 14, 17,\n",
            "         0, 19])\n",
            "Images shape: torch.Size([60, 3, 224, 224])\n",
            "Labels shape: torch.Size([60])\n",
            "tensor([ 4, 18, 17,  7, 11, 13, 16,  0, 10,  3,  4,  5,  2,  1,  0,  8, 15, 10,\n",
            "        17,  9, 19,  5, 17,  0,  8, 19, 13,  4, 14, 12,  8, 18,  2,  3,  6,  2,\n",
            "        15, 14, 12, 19,  3, 18,  7,  1,  5,  9,  1,  7,  9,  6, 15, 11, 13, 11,\n",
            "        16, 16, 14, 12, 10,  6])\n",
            "Images shape: torch.Size([60, 3, 224, 224])\n",
            "Labels shape: torch.Size([60])\n",
            "tensor([10, 15,  9, 10, 12, 19, 14,  0,  4, 18, 17,  7, 13,  0, 12, 11,  2,  7,\n",
            "         5,  9,  6, 19,  5,  2, 10, 13,  6,  1, 15,  1,  4,  8,  2,  4,  1, 12,\n",
            "         5, 18,  7, 11,  0, 11, 19, 16, 16, 14,  3, 13, 18,  8, 16,  3,  9,  3,\n",
            "        15, 17,  6,  8, 17, 14])\n"
          ]
        }
      ],
      "source": [
        "for images, labels in train_loader:\n",
        "    print(f\"Images shape: {images.shape}\")\n",
        "    print(f\"Labels shape: {labels.shape}\")\n",
        "    print(labels)\n",
        "    break  # Break after the first batch to avoid printing all batches\n",
        "\n",
        "for images, labels in valid_loader:\n",
        "    print(f\"Images shape: {images.shape}\")\n",
        "    print(f\"Labels shape: {labels.shape}\")\n",
        "    print(labels)\n",
        "    break  # Break after the first batch to avoid printing all batches\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    print(f\"Images shape: {images.shape}\")\n",
        "    print(f\"Labels shape: {labels.shape}\")\n",
        "    print(labels)\n",
        "    break  # Break after the first batch to avoid printing all batches\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "xUL9XgPhf4hp",
        "outputId": "cbce94fd-faf9-4230-ec2e-d582247e9d78"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision.utils import make_grid\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "# Function to plot images in a grid\n",
        "def plot_images(images, title=\"Images\"):\n",
        "    # Create a grid of images\n",
        "    grid = make_grid(images, nrow=8, padding=2)\n",
        "\n",
        "    # Convert to numpy array for plotting\n",
        "    np_grid = grid.numpy().transpose((1, 2, 0))  # Convert from CHW to HWC\n",
        "\n",
        "    # Plot the grid\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.imshow(np_grid)\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Function to get and plot images for a specific label from the dataset\n",
        "def plot_images_by_label(label, train_dataset, valid_dataset, test_dataset, transform=None):\n",
        "    # Get all images belonging to the given label from each dataset\n",
        "    train_images = []\n",
        "    train_labels = []\n",
        "\n",
        "    for img, lbl in train_dataset:\n",
        "        if lbl == label:\n",
        "            train_images.append(img)\n",
        "            train_labels.append(lbl)\n",
        "\n",
        "    valid_images = []\n",
        "    valid_labels = []\n",
        "\n",
        "    for img, lbl in valid_dataset:\n",
        "        if lbl == label:\n",
        "            valid_images.append(img)\n",
        "            valid_labels.append(lbl)\n",
        "\n",
        "    test_images = []\n",
        "    test_labels = []\n",
        "\n",
        "    for img, lbl in test_dataset:\n",
        "        if lbl == label:\n",
        "            test_images.append(img)\n",
        "            test_labels.append(lbl)\n",
        "\n",
        "    # Plot the images for the train set\n",
        "    if train_images:\n",
        "        plot_images(train_images, title=f\"Train Set - Label {label}\")\n",
        "    else:\n",
        "        print(f\"No images found for Label {label} in Train Set.\")\n",
        "\n",
        "    # Plot the images for the validation set\n",
        "    if valid_images:\n",
        "        plot_images(valid_images, title=f\"Validation Set - Label {label}\")\n",
        "    else:\n",
        "        print(f\"No images found for Label {label} in Validation Set.\")\n",
        "\n",
        "    # Plot the images for the test set\n",
        "    if test_images:\n",
        "        plot_images(test_images, title=f\"Test Set - Label {label}\")\n",
        "    else:\n",
        "        print(f\"No images found for Label {label} in Test Set.\")\n",
        "\n",
        "# Pick a label\n",
        "label_to_plot = list(set(selected_images[\"label\"]))[155]\n",
        "\n",
        "# Call the function to plot images for the selected label\n",
        "plot_images_by_label(label_to_plot, train_dataset, valid_dataset, test_dataset, transform=transform)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "kIBd4ZHes9D0",
        "outputId": "d45c6712-c3a8-4b26-e3c0-130c4d1f6744"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Function to denormalize the images for visualization\n",
        "def denormalize(image_tensor):\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    image = image_tensor.permute(1, 2, 0).numpy()  # Convert to HWC format\n",
        "    image = std * image + mean  # Reverse normalization\n",
        "    image = np.clip(image, 0, 1)  # Clip values to [0, 1] for valid image range\n",
        "    return image\n",
        "\n",
        "# Function to display images with labels from a DataLoader\n",
        "def display_batch(data_loader, title=\"Batch\"):\n",
        "    # Get a batch of data\n",
        "    images, labels = next(iter(data_loader))\n",
        "\n",
        "    # Plot the images in a grid\n",
        "    batch_size = len(images)\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for i in range(min(batch_size, 36)):  # Display at most 16 images\n",
        "        plt.subplot(6, 6, i + 1)  # 4x4 grid\n",
        "        image = denormalize(images[i])  # Denormalize the image\n",
        "        plt.imshow(image)\n",
        "        plt.title(f\"Label: {labels[i].item()}\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "print(\"Training Batch:\")\n",
        "display_batch(train_loader, title=\"Training Batch\")\n",
        "\n",
        "print(\"Validation Batch:\")\n",
        "display_batch(valid_loader, title=\"Validation Batch\")\n",
        "\n",
        "print(\"Test Batch:\")\n",
        "display_batch(test_loader, title=\"Test Batch\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "ISh2ZaJOnAen",
        "outputId": "0dd57d49-6744-4bfd-b863-ab861c6111c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\parsak\\AppData\\Local\\anaconda3\\envs\\py311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\parsak\\AppData\\Local\\anaconda3\\envs\\py311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the pre-trained ResNet18 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Modify the final fully connected layer to match the number of labels (for CelebA, you have N unique labels)\n",
        "num_labels = len(selected_labels)  # This is the number of unique labels after filtering\n",
        "model.fc = nn.Linear(model.fc.in_features, num_labels)\n",
        "\n",
        "# Freeze all layers except the final fully connected layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the last fully connected layer to allow it to be trained\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Move the model to the appropriate device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Multi-class classification loss function\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)  # Only optimize the last layer\n",
        "\n",
        "# Number of epochs for training\n",
        "num_epochs = 10\n",
        "\n",
        "# Training and validation loop\n",
        "def train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs=10):\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        # Train loop\n",
        "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Train)\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "            total_train += labels.size(0)\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        train_accuracy = correct_train / total_train\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        correct_valid = 0\n",
        "        total_valid = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in valid_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct_valid += (predicted == labels).sum().item()\n",
        "                total_valid += labels.size(0)\n",
        "\n",
        "        # Calculate validation accuracy\n",
        "        valid_accuracy = correct_valid / total_valid\n",
        "\n",
        "        # Print loss and accuracy for each epoch\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, \"\n",
        "              f\"Train Accuracy: {train_accuracy:.4f}, Validation Accuracy: {valid_accuracy:.4f}\")\n",
        "\n",
        "        # Save the model if validation accuracy is better\n",
        "        if valid_accuracy > best_accuracy:\n",
        "            best_accuracy = valid_accuracy\n",
        "            torch.save(model.state_dict(), \"best_resnet18.pth\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/50 (Train): 100%|██████████| 4/4 [00:11<00:00,  3.00s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Loss: 3.1670, Train Accuracy: 0.0458, Validation Accuracy: 0.0333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/50, Loss: 3.0916, Train Accuracy: 0.0563, Validation Accuracy: 0.0667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/50, Loss: 3.0143, Train Accuracy: 0.0708, Validation Accuracy: 0.1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/50, Loss: 2.9349, Train Accuracy: 0.1125, Validation Accuracy: 0.1167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/50, Loss: 2.8612, Train Accuracy: 0.1313, Validation Accuracy: 0.1667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/50 (Train): 100%|██████████| 4/4 [00:09<00:00,  2.26s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/50, Loss: 2.7932, Train Accuracy: 0.1708, Validation Accuracy: 0.1667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/50 (Train): 100%|██████████| 4/4 [00:12<00:00,  3.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/50, Loss: 2.7332, Train Accuracy: 0.2146, Validation Accuracy: 0.2000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.20s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/50, Loss: 2.6572, Train Accuracy: 0.2542, Validation Accuracy: 0.2333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/50 (Train): 100%|██████████| 4/4 [00:09<00:00,  2.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/50, Loss: 2.5839, Train Accuracy: 0.3063, Validation Accuracy: 0.2667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/50 (Train): 100%|██████████| 4/4 [00:09<00:00,  2.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/50, Loss: 2.5113, Train Accuracy: 0.3542, Validation Accuracy: 0.2667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/50 (Train): 100%|██████████| 4/4 [00:09<00:00,  2.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/50, Loss: 2.4481, Train Accuracy: 0.3854, Validation Accuracy: 0.3167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/50, Loss: 2.3942, Train Accuracy: 0.4354, Validation Accuracy: 0.4000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.17s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/50, Loss: 2.3338, Train Accuracy: 0.4375, Validation Accuracy: 0.4167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/50 (Train): 100%|██████████| 4/4 [00:09<00:00,  2.26s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/50, Loss: 2.2686, Train Accuracy: 0.4792, Validation Accuracy: 0.4167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/50 (Train): 100%|██████████| 4/4 [00:09<00:00,  2.38s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/50, Loss: 2.2053, Train Accuracy: 0.5271, Validation Accuracy: 0.4167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/50 (Train): 100%|██████████| 4/4 [00:09<00:00,  2.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/50, Loss: 2.1637, Train Accuracy: 0.5458, Validation Accuracy: 0.4333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/50, Loss: 2.1051, Train Accuracy: 0.5604, Validation Accuracy: 0.4667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/50, Loss: 2.0557, Train Accuracy: 0.6000, Validation Accuracy: 0.5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/50, Loss: 1.9963, Train Accuracy: 0.6271, Validation Accuracy: 0.5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/50, Loss: 1.9486, Train Accuracy: 0.6396, Validation Accuracy: 0.5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/50 (Train): 100%|██████████| 4/4 [00:10<00:00,  2.55s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/50, Loss: 1.9112, Train Accuracy: 0.6521, Validation Accuracy: 0.5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/50, Loss: 1.8573, Train Accuracy: 0.6792, Validation Accuracy: 0.5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/50 (Train): 100%|██████████| 4/4 [00:09<00:00,  2.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/50, Loss: 1.8207, Train Accuracy: 0.7042, Validation Accuracy: 0.5667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.20s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/50, Loss: 1.7824, Train Accuracy: 0.7229, Validation Accuracy: 0.5667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/50 (Train): 100%|██████████| 4/4 [00:09<00:00,  2.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/50, Loss: 1.7448, Train Accuracy: 0.7396, Validation Accuracy: 0.5833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26/50, Loss: 1.7078, Train Accuracy: 0.7500, Validation Accuracy: 0.6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.20s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27/50, Loss: 1.6666, Train Accuracy: 0.7583, Validation Accuracy: 0.6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28/50, Loss: 1.6338, Train Accuracy: 0.7771, Validation Accuracy: 0.6167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29/50, Loss: 1.6031, Train Accuracy: 0.7792, Validation Accuracy: 0.6167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30/50 (Train): 100%|██████████| 4/4 [00:09<00:00,  2.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30/50, Loss: 1.5741, Train Accuracy: 0.7854, Validation Accuracy: 0.6333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31/50 (Train): 100%|██████████| 4/4 [00:09<00:00,  2.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31/50, Loss: 1.5406, Train Accuracy: 0.8000, Validation Accuracy: 0.6167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32/50, Loss: 1.5161, Train Accuracy: 0.7979, Validation Accuracy: 0.6167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 33/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33/50, Loss: 1.4887, Train Accuracy: 0.8167, Validation Accuracy: 0.6167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 34/50 (Train): 100%|██████████| 4/4 [00:09<00:00,  2.26s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34/50, Loss: 1.4534, Train Accuracy: 0.8187, Validation Accuracy: 0.6167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 35/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.20s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35/50, Loss: 1.4249, Train Accuracy: 0.8250, Validation Accuracy: 0.6167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 36/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36/50, Loss: 1.4058, Train Accuracy: 0.8396, Validation Accuracy: 0.6167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 37/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37/50, Loss: 1.3818, Train Accuracy: 0.8458, Validation Accuracy: 0.6167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 38/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38/50, Loss: 1.3596, Train Accuracy: 0.8396, Validation Accuracy: 0.6167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 39/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39/50, Loss: 1.3373, Train Accuracy: 0.8688, Validation Accuracy: 0.6333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 40/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40/50, Loss: 1.2976, Train Accuracy: 0.8667, Validation Accuracy: 0.6500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 41/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41/50, Loss: 1.2914, Train Accuracy: 0.8625, Validation Accuracy: 0.6333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 42/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42/50, Loss: 1.2663, Train Accuracy: 0.8667, Validation Accuracy: 0.6333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 43/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.20s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43/50, Loss: 1.2475, Train Accuracy: 0.8646, Validation Accuracy: 0.6333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 44/50 (Train): 100%|██████████| 4/4 [00:09<00:00,  2.26s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44/50, Loss: 1.2247, Train Accuracy: 0.8708, Validation Accuracy: 0.6333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 45/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45/50, Loss: 1.2086, Train Accuracy: 0.8750, Validation Accuracy: 0.6333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 46/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46/50, Loss: 1.1930, Train Accuracy: 0.8771, Validation Accuracy: 0.6333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 47/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47/50, Loss: 1.1687, Train Accuracy: 0.8833, Validation Accuracy: 0.6667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 48/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48/50, Loss: 1.1514, Train Accuracy: 0.8854, Validation Accuracy: 0.6667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 49/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49/50, Loss: 1.1486, Train Accuracy: 0.8875, Validation Accuracy: 0.6667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 50/50 (Train): 100%|██████████| 4/4 [00:08<00:00,  2.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50/50, Loss: 1.1256, Train Accuracy: 0.8896, Validation Accuracy: 0.6500\n"
          ]
        }
      ],
      "source": [
        "# Call the training function with the training and validation dataloaders\n",
        "train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.6667\n",
            "Confusion Matrix:\n",
            " [[2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 2 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    # Load the best model weights if saved\n",
        "    model.load_state_dict(torch.load(\"best_resnet18.pth\"))\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    # No gradient computation during evaluation\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Get the predictions\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # Compute accuracy\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(num_labels), yticklabels=range(num_labels))\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "# Call the function with your test dataloader\n",
        "evaluate_model(model, test_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True: tensor(4)  - predicted: tensor(9) ['-0.44', '-0.53', '0.84', '-0.66', '0.72', '0.77', '0.25', '-0.11', '-2.11', '2.24', '-0.86', '-0.52', '-0.18', '-0.24', '-1.03', '1.39', '0.08', '-0.80', '-0.63', '-0.94']\n",
            "True: tensor(18)  - predicted: tensor(18) ['-2.32', '-1.56', '1.01', '1.58', '0.35', '-0.76', '-2.23', '0.30', '-0.18', '-0.23', '0.36', '1.02', '-0.43', '1.23', '-0.94', '1.10', '0.28', '0.02', '1.66', '-0.36']\n",
            "True: tensor(17)  - predicted: tensor(13) ['-1.55', '-2.60', '-0.68', '1.82', '0.93', '-0.68', '-2.09', '1.36', '0.36', '-1.75', '1.74', '0.71', '0.11', '2.61', '-2.05', '0.89', '0.53', '0.39', '1.54', '-1.18']\n",
            "True: tensor(7)  - predicted: tensor(18) ['-0.65', '-0.92', '0.70', '0.80', '-0.09', '0.40', '-0.79', '0.81', '-1.17', '-0.25', '-0.12', '1.41', '-0.14', '-0.48', '-1.54', '0.45', '0.70', '-0.95', '1.73', '-0.14']\n",
            "True: tensor(11)  - predicted: tensor(11) ['-1.59', '-1.00', '-0.59', '0.62', '-0.16', '-0.85', '-0.72', '0.98', '-0.04', '0.29', '0.04', '1.40', '0.65', '-0.65', '-1.35', '0.52', '0.10', '-0.85', '0.83', '-0.08']\n",
            "True: tensor(13)  - predicted: tensor(13) ['0.31', '-2.38', '-0.09', '1.71', '1.00', '-0.67', '-0.98', '0.22', '-0.58', '-1.72', '1.72', '0.08', '-0.52', '3.61', '-2.35', '0.41', '0.83', '0.18', '0.73', '-1.68']\n",
            "True: tensor(16)  - predicted: tensor(16) ['-0.59', '-1.21', '1.65', '-1.41', '1.16', '1.44', '-0.73', '1.39', '-1.59', '-0.38', '-0.31', '0.02', '0.19', '-0.43', '-1.78', '2.73', '3.17', '0.18', '0.66', '-0.84']\n",
            "True: tensor(0)  - predicted: tensor(0) ['1.58', '0.90', '-1.47', '-0.95', '-1.24', '1.24', '0.00', '0.26', '0.29', '-0.72', '-1.00', '0.89', '-0.29', '-1.37', '0.79', '0.42', '1.03', '-0.43', '0.06', '1.05']\n",
            "True: tensor(10)  - predicted: tensor(10) ['0.82', '-0.19', '-0.71', '0.22', '-0.77', '-0.76', '-1.35', '0.01', '-0.72', '0.07', '1.54', '0.06', '0.09', '0.36', '0.47', '-0.69', '-0.55', '0.09', '0.48', '-0.18']\n",
            "True: tensor(3)  - predicted: tensor(0) ['1.39', '0.52', '-0.87', '0.19', '-1.87', '0.34', '0.11', '-0.72', '-0.87', '1.15', '0.66', '0.75', '0.88', '-0.64', '-1.12', '0.46', '-0.70', '-0.78', '-1.48', '0.36']\n",
            "True: tensor(4)  - predicted: tensor(4) ['-1.36', '-1.52', '1.57', '0.21', '2.69', '-0.79', '-0.33', '0.58', '-1.11', '-0.41', '-0.02', '1.46', '-0.37', '-0.25', '-1.65', '0.96', '0.77', '-0.40', '0.50', '0.47']\n",
            "True: tensor(5)  - predicted: tensor(5) ['0.59', '-1.45', '0.77', '-0.34', '0.67', '1.63', '-1.13', '0.43', '-1.30', '-0.52', '-1.14', '0.40', '0.40', '-0.78', '-0.76', '1.05', '1.48', '-0.56', '-0.59', '-0.28']\n",
            "True: tensor(2)  - predicted: tensor(4) ['-0.40', '-1.12', '1.02', '-0.79', '1.64', '-0.12', '-1.21', '0.46', '-1.66', '-0.25', '0.08', '0.96', '0.21', '0.46', '-0.40', '0.39', '1.12', '0.07', '0.10', '-1.17']\n",
            "True: tensor(1)  - predicted: tensor(6) ['-0.77', '2.67', '0.47', '-1.39', '-0.28', '-1.79', '3.04', '0.96', '-2.81', '1.83', '-1.48', '-1.34', '-0.06', '-1.83', '0.50', '0.37', '-0.95', '-1.31', '-1.15', '2.11']\n",
            "True: tensor(0)  - predicted: tensor(0) ['2.77', '0.07', '-0.25', '-0.77', '-1.72', '1.44', '0.18', '-0.53', '-0.14', '0.10', '-0.10', '0.39', '0.84', '-1.01', '-1.02', '0.26', '-0.62', '-0.09', '-0.10', '0.96']\n",
            "True: tensor(8)  - predicted: tensor(8) ['-1.34', '-0.86', '-0.96', '0.90', '-0.93', '-2.71', '-0.98', '0.04', '2.52', '0.28', '1.61', '-0.48', '-0.93', '1.70', '0.23', '0.10', '-0.48', '2.32', '0.41', '-0.29']\n",
            "True: tensor(15)  - predicted: tensor(15) ['-0.77', '-1.05', '-0.30', '0.20', '0.30', '-0.35', '0.01', '0.61', '-0.22', '0.56', '-0.17', '0.22', '-0.18', '-0.08', '-1.35', '1.00', '0.99', '0.44', '0.12', '0.07']\n",
            "True: tensor(10)  - predicted: tensor(10) ['1.27', '-0.20', '0.20', '1.36', '-0.95', '-0.02', '-1.29', '0.06', '-0.48', '-0.16', '2.00', '-0.73', '-0.31', '-0.04', '-0.45', '-0.30', '-0.47', '0.90', '0.25', '-0.57']\n",
            "True: tensor(17)  - predicted: tensor(17) ['-0.75', '-2.01', '-0.64', '1.58', '0.52', '-0.85', '-1.60', '-0.43', '0.01', '0.57', '1.79', '-1.03', '-0.66', '0.69', '-1.62', '0.63', '0.15', '3.07', '0.63', '-0.77']\n",
            "True: tensor(9)  - predicted: tensor(9) ['-0.93', '0.92', '-0.42', '0.01', '-2.10', '-0.33', '0.66', '-1.20', '-0.15', '2.69', '0.23', '-0.71', '0.79', '-0.61', '0.29', '-0.37', '-1.15', '0.58', '-1.16', '0.93']\n",
            "True: tensor(19)  - predicted: tensor(6) ['-0.30', '1.53', '-0.20', '-0.94', '-0.11', '-0.19', '2.42', '-1.84', '-0.91', '0.39', '-0.01', '-0.47', '0.65', '-1.20', '0.14', '0.15', '-0.59', '-0.33', '0.14', '1.68']\n",
            "True: tensor(5)  - predicted: tensor(14) ['0.41', '-0.54', '-0.00', '-1.82', '-0.57', '0.89', '-0.00', '1.06', '-0.90', '1.07', '-1.79', '0.92', '0.85', '-1.04', '1.47', '-0.17', '-0.13', '-0.44', '-0.23', '0.26']\n",
            "True: tensor(17)  - predicted: tensor(17) ['-0.97', '-1.60', '-0.97', '1.49', '-0.71', '-0.01', '-1.37', '-0.40', '1.58', '-0.16', '2.55', '-0.99', '-1.18', '1.50', '-1.13', '0.60', '-0.60', '2.86', '1.11', '-1.55']\n",
            "True: tensor(0)  - predicted: tensor(0) ['4.23', '0.80', '0.29', '-1.44', '-0.23', '0.91', '-0.52', '-0.02', '-1.38', '-0.50', '-1.68', '0.43', '0.34', '-1.53', '0.74', '-1.12', '1.02', '-0.70', '-0.88', '0.67']\n",
            "True: tensor(8)  - predicted: tensor(13) ['-0.43', '-1.07', '-0.63', '1.00', '-0.50', '-0.78', '-2.56', '1.28', '0.81', '-0.23', '0.26', '-0.10', '-0.85', '2.12', '-0.11', '0.18', '-0.07', '1.32', '-0.16', '-1.89']\n",
            "True: tensor(19)  - predicted: tensor(19) ['-0.58', '1.43', '0.50', '-1.16', '0.12', '-0.31', '1.01', '0.33', '-1.17', '1.33', '-0.32', '0.06', '-0.39', '-1.26', '0.91', '-0.63', '-0.71', '-0.21', '-0.70', '1.92']\n",
            "True: tensor(13)  - predicted: tensor(13) ['-0.97', '-2.22', '-0.56', '1.27', '0.64', '-0.71', '-0.97', '-0.77', '0.71', '-0.96', '1.65', '0.07', '-0.27', '2.01', '-0.67', '-0.19', '0.18', '0.78', '1.64', '-1.02']\n",
            "True: tensor(4)  - predicted: tensor(4) ['-0.88', '-1.74', '2.29', '0.49', '2.31', '-0.22', '-0.05', '0.05', '-1.84', '-0.10', '0.17', '0.60', '-0.27', '-0.55', '-1.39', '0.28', '1.55', '-1.09', '0.73', '0.07']\n",
            "True: tensor(14)  - predicted: tensor(14) ['0.02', '0.50', '-1.88', '-0.42', '-1.06', '0.32', '-0.34', '1.11', '-0.27', '0.57', '-0.14', '-0.44', '0.30', '0.04', '3.31', '-0.76', '-1.42', '1.33', '-0.77', '0.29']\n",
            "True: tensor(12)  - predicted: tensor(12) ['-0.34', '-0.60', '-0.09', '0.19', '-1.13', '0.58', '-1.97', '1.09', '-1.03', '-0.32', '-0.03', '1.08', '2.04', '-0.44', '-1.09', '0.25', '0.09', '-0.55', '0.46', '-0.24']\n",
            "True: tensor(8)  - predicted: tensor(8) ['0.42', '-1.04', '-0.78', '0.63', '-0.22', '-0.96', '-1.17', '-0.58', '2.59', '-0.25', '1.71', '-0.74', '-0.36', '1.02', '-1.03', '0.91', '0.77', '0.94', '0.04', '-1.29']\n",
            "True: tensor(18)  - predicted: tensor(18) ['-0.46', '-1.14', '-0.20', '0.52', '-0.03', '-1.03', '-0.65', '0.85', '-0.62', '-0.30', '0.70', '1.06', '0.86', '0.61', '0.01', '-0.23', '-0.17', '-0.20', '2.64', '-0.08']\n",
            "True: tensor(2)  - predicted: tensor(2) ['-0.12', '-1.09', '2.18', '-0.28', '0.74', '0.61', '-0.98', '0.63', '-1.42', '-1.28', '-0.97', '1.70', '0.41', '-0.83', '-0.91', '1.08', '1.84', '-0.71', '0.05', '-0.29']\n",
            "True: tensor(3)  - predicted: tensor(3) ['-1.26', '-1.11', '-0.39', '2.49', '0.48', '-1.22', '-0.84', '-0.83', '0.57', '-0.07', '0.92', '0.94', '-0.47', '1.22', '-1.42', '0.45', '-0.63', '-0.19', '1.25', '0.37']\n",
            "True: tensor(6)  - predicted: tensor(6) ['0.08', '-0.46', '0.24', '-0.87', '-0.11', '0.28', '1.10', '-0.12', '-0.93', '0.51', '-0.62', '-0.18', '-0.68', '-1.27', '0.49', '0.55', '0.28', '-0.34', '-0.10', '0.55']\n",
            "True: tensor(2)  - predicted: tensor(5) ['0.50', '-2.43', '1.79', '-0.96', '1.95', '2.31', '-0.70', '-0.05', '-1.74', '-0.99', '-0.80', '0.62', '0.23', '-1.06', '-1.55', '1.57', '2.07', '-0.23', '0.71', '-0.80']\n",
            "True: tensor(15)  - predicted: tensor(2) ['-1.19', '0.24', '0.72', '0.24', '0.39', '-0.35', '-0.18', '0.39', '-1.91', '0.71', '-0.67', '0.23', '0.03', '-0.41', '-1.07', '0.30', '0.33', '-0.12', '0.26', '0.47']\n",
            "True: tensor(14)  - predicted: tensor(14) ['0.27', '1.20', '-0.66', '-0.60', '-0.99', '-0.35', '2.06', '-1.78', '-0.55', '0.50', '-0.31', '-0.80', '-0.25', '-0.97', '2.36', '-1.17', '-1.34', '-1.22', '0.57', '1.78']\n",
            "True: tensor(12)  - predicted: tensor(12) ['1.26', '-0.79', '0.32', '-0.66', '-1.34', '2.25', '-0.82', '-0.52', '-1.57', '1.59', '-0.47', '0.97', '2.28', '-1.14', '-1.46', '-0.11', '0.41', '-0.45', '-0.01', '0.10']\n",
            "True: tensor(19)  - predicted: tensor(12) ['-0.35', '0.20', '-0.86', '-0.26', '-0.52', '0.74', '0.53', '0.23', '-1.46', '-0.15', '-0.79', '0.40', '0.98', '-1.21', '0.98', '0.44', '-0.22', '-0.72', '0.02', '0.91']\n",
            "True: tensor(3)  - predicted: tensor(3) ['-1.29', '-1.40', '0.10', '1.99', '-0.49', '-0.82', '-2.60', '-0.78', '1.41', '-0.57', '1.85', '-0.04', '-1.32', '1.83', '-0.26', '-0.06', '0.25', '0.75', '0.81', '-1.23']\n",
            "True: tensor(18)  - predicted: tensor(18) ['-1.17', '-2.11', '-0.05', '0.87', '0.86', '0.12', '-0.51', '0.04', '-0.48', '-0.25', '0.31', '0.90', '0.12', '0.47', '-0.87', '0.14', '0.14', '-0.47', '2.06', '-1.22']\n",
            "True: tensor(7)  - predicted: tensor(7) ['-1.62', '-0.42', '0.55', '0.74', '-0.03', '-0.17', '-1.49', '1.95', '-1.02', '0.05', '-0.66', '0.54', '-0.62', '-0.61', '-1.23', '1.64', '0.80', '-0.03', '0.82', '-0.40']\n",
            "True: tensor(1)  - predicted: tensor(1) ['-0.11', '2.61', '-0.17', '-1.21', '-1.13', '-1.14', '1.79', '-0.57', '-0.97', '0.43', '-0.57', '0.26', '0.71', '-1.17', '0.79', '-0.22', '-0.52', '-0.80', '-0.54', '2.44']\n",
            "True: tensor(5)  - predicted: tensor(5) ['1.70', '-2.13', '-0.14', '-0.59', '-0.31', '2.00', '-1.77', '-0.06', '-1.20', '0.17', '0.02', '-0.52', '1.56', '-0.36', '-0.09', '-0.04', '0.71', '-0.11', '0.74', '-1.06']\n",
            "True: tensor(9)  - predicted: tensor(9) ['0.49', '0.34', '0.69', '-0.19', '-0.47', '-0.66', '0.17', '-0.17', '-0.68', '1.23', '-0.40', '-0.36', '0.55', '-0.37', '-0.18', '0.13', '0.27', '-0.89', '-0.66', '0.07']\n",
            "True: tensor(1)  - predicted: tensor(1) ['-1.35', '3.02', '0.70', '-0.52', '-1.46', '-0.69', '1.79', '0.01', '-0.93', '0.87', '-1.26', '-0.05', '-0.41', '-1.16', '0.23', '-0.69', '0.01', '-0.64', '-0.57', '1.91']\n",
            "True: tensor(7)  - predicted: tensor(16) ['-1.91', '-1.55', '0.90', '0.67', '1.12', '-0.76', '-1.15', '1.91', '-0.67', '-0.40', '0.66', '0.15', '0.30', '0.55', '-2.06', '1.61', '2.34', '-0.18', '1.49', '-0.99']\n",
            "True: tensor(9)  - predicted: tensor(10) ['0.23', '-0.29', '-1.61', '0.49', '0.15', '-1.54', '0.12', '-0.87', '0.91', '0.34', '1.31', '-0.17', '0.01', '1.22', '1.11', '0.32', '-1.42', '-0.64', '0.73', '0.71']\n",
            "True: tensor(6)  - predicted: tensor(6) ['-0.53', '0.11', '0.65', '-0.66', '-0.34', '-0.34', '1.79', '-0.05', '-2.12', '1.45', '-0.85', '-1.07', '-0.45', '-1.16', '0.50', '0.20', '-0.65', '-0.94', '-0.51', '0.26']\n",
            "True: tensor(15)  - predicted: tensor(2) ['0.23', '-0.22', '1.59', '-0.63', '0.11', '0.37', '0.05', '0.70', '-1.72', '0.82', '-0.09', '-0.08', '-0.20', '-0.78', '-1.35', '1.30', '-0.20', '0.15', '-0.91', '-1.42']\n",
            "True: tensor(11)  - predicted: tensor(7) ['-0.66', '-1.54', '0.79', '0.49', '1.23', '-1.05', '-0.24', '1.47', '-0.25', '-0.87', '-0.11', '1.03', '-0.35', '1.14', '-1.44', '0.54', '0.68', '-0.13', '0.34', '-0.82']\n",
            "True: tensor(13)  - predicted: tensor(8) ['-0.30', '-1.09', '-1.11', '1.69', '-1.16', '-1.00', '-2.32', '-0.86', '2.69', '-0.99', '1.90', '-0.27', '-0.34', '1.58', '-0.24', '-0.70', '-0.42', '0.99', '0.71', '-0.81']\n",
            "True: tensor(11)  - predicted: tensor(17) ['-1.50', '-1.95', '-0.67', '1.42', '0.96', '-1.20', '-1.55', '0.22', '0.34', '0.10', '0.13', '0.20', '-0.80', '1.14', '-0.35', '0.13', '0.51', '1.97', '0.65', '-1.02']\n",
            "True: tensor(16)  - predicted: tensor(17) ['-0.15', '-0.32', '-0.51', '0.18', '-0.34', '-0.10', '-1.18', '0.17', '-1.02', '0.46', '-0.14', '-0.45', '0.86', '0.32', '0.22', '0.09', '0.46', '1.08', '-0.65', '0.04']\n",
            "True: tensor(16)  - predicted: tensor(16) ['-0.27', '-1.76', '2.09', '-0.30', '1.67', '1.17', '-0.94', '0.58', '-1.96', '-0.86', '-0.66', '0.67', '0.73', '-0.81', '-1.97', '1.22', '2.25', '-1.04', '0.79', '-1.54']\n",
            "True: tensor(14)  - predicted: tensor(14) ['1.31', '0.80', '-0.77', '0.26', '-1.62', '-0.31', '0.73', '-1.42', '-0.05', '-0.29', '-0.34', '-0.57', '-0.16', '-1.03', '3.81', '-0.83', '-1.37', '-0.62', '0.26', '1.27']\n",
            "True: tensor(12)  - predicted: tensor(7) ['0.12', '-0.70', '-0.78', '0.35', '-1.58', '-0.07', '-0.58', '1.28', '-1.13', '-0.71', '-0.25', '1.26', '1.09', '-0.57', '0.17', '-1.12', '0.14', '-0.64', '0.33', '1.13']\n",
            "True: tensor(10)  - predicted: tensor(10) ['0.08', '-0.77', '0.04', '-0.16', '0.42', '-0.33', '-0.30', '0.01', '-0.37', '0.60', '0.85', '-0.73', '0.20', '0.58', '-0.81', '-0.19', '0.01', '-0.18', '0.14', '0.06']\n",
            "True: tensor(6)  - predicted: tensor(6) ['1.55', '0.09', '0.07', '-0.91', '0.20', '-0.06', '1.80', '-0.92', '-1.44', '0.40', '-0.29', '-0.31', '0.45', '0.13', '-0.44', '-1.05', '-0.72', '-0.36', '0.07', '0.80']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for images, labels in valid_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(torch.max(outputs, 1)[1])):\n",
        "    formatted_tensor = [f\"{val:.2f}\" for val in outputs[i].tolist()]\n",
        "    print('True:',labels[i], ' - predicted:', torch.max(outputs, 1)[1][i], formatted_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True: tensor(4)  - predicted: tensor(9) ['-0.44', '-0.53', '0.84', '-0.66', '0.72', '0.77', '0.25', '-0.11', '-2.11', '2.24', '-0.86', '-0.52', '-0.18', '-0.24', '-1.03', '1.39', '0.08', '-0.80', '-0.63', '-0.94']\n",
            "True: tensor(18)  - predicted: tensor(18) ['-2.32', '-1.56', '1.01', '1.58', '0.35', '-0.76', '-2.23', '0.30', '-0.18', '-0.23', '0.36', '1.02', '-0.43', '1.23', '-0.94', '1.10', '0.28', '0.02', '1.66', '-0.36']\n",
            "True: tensor(17)  - predicted: tensor(13) ['-1.55', '-2.60', '-0.68', '1.82', '0.93', '-0.68', '-2.09', '1.36', '0.36', '-1.75', '1.74', '0.71', '0.11', '2.61', '-2.05', '0.89', '0.53', '0.39', '1.54', '-1.18']\n",
            "True: tensor(7)  - predicted: tensor(18) ['-0.65', '-0.92', '0.70', '0.80', '-0.09', '0.40', '-0.79', '0.81', '-1.17', '-0.25', '-0.12', '1.41', '-0.14', '-0.48', '-1.54', '0.45', '0.70', '-0.95', '1.73', '-0.14']\n",
            "True: tensor(11)  - predicted: tensor(11) ['-1.59', '-1.00', '-0.59', '0.62', '-0.16', '-0.85', '-0.72', '0.98', '-0.04', '0.29', '0.04', '1.40', '0.65', '-0.65', '-1.35', '0.52', '0.10', '-0.85', '0.83', '-0.08']\n",
            "True: tensor(13)  - predicted: tensor(13) ['0.31', '-2.38', '-0.09', '1.71', '1.00', '-0.67', '-0.98', '0.22', '-0.58', '-1.72', '1.72', '0.08', '-0.52', '3.61', '-2.35', '0.41', '0.83', '0.18', '0.73', '-1.68']\n",
            "True: tensor(16)  - predicted: tensor(16) ['-0.59', '-1.21', '1.65', '-1.41', '1.16', '1.44', '-0.73', '1.39', '-1.59', '-0.38', '-0.31', '0.02', '0.19', '-0.43', '-1.78', '2.73', '3.17', '0.18', '0.66', '-0.84']\n",
            "True: tensor(0)  - predicted: tensor(0) ['1.58', '0.90', '-1.47', '-0.95', '-1.24', '1.24', '0.00', '0.26', '0.29', '-0.72', '-1.00', '0.89', '-0.29', '-1.37', '0.79', '0.42', '1.03', '-0.43', '0.06', '1.05']\n",
            "True: tensor(10)  - predicted: tensor(10) ['0.82', '-0.19', '-0.71', '0.22', '-0.77', '-0.76', '-1.35', '0.01', '-0.72', '0.07', '1.54', '0.06', '0.09', '0.36', '0.47', '-0.69', '-0.55', '0.09', '0.48', '-0.18']\n",
            "True: tensor(3)  - predicted: tensor(0) ['1.39', '0.52', '-0.87', '0.19', '-1.87', '0.34', '0.11', '-0.72', '-0.87', '1.15', '0.66', '0.75', '0.88', '-0.64', '-1.12', '0.46', '-0.70', '-0.78', '-1.48', '0.36']\n",
            "True: tensor(4)  - predicted: tensor(4) ['-1.36', '-1.52', '1.57', '0.21', '2.69', '-0.79', '-0.33', '0.58', '-1.11', '-0.41', '-0.02', '1.46', '-0.37', '-0.25', '-1.65', '0.96', '0.77', '-0.40', '0.50', '0.47']\n",
            "True: tensor(5)  - predicted: tensor(5) ['0.59', '-1.45', '0.77', '-0.34', '0.67', '1.63', '-1.13', '0.43', '-1.30', '-0.52', '-1.14', '0.40', '0.40', '-0.78', '-0.76', '1.05', '1.48', '-0.56', '-0.59', '-0.28']\n",
            "True: tensor(2)  - predicted: tensor(4) ['-0.40', '-1.12', '1.02', '-0.79', '1.64', '-0.12', '-1.21', '0.46', '-1.66', '-0.25', '0.08', '0.96', '0.21', '0.46', '-0.40', '0.39', '1.12', '0.07', '0.10', '-1.17']\n",
            "True: tensor(1)  - predicted: tensor(6) ['-0.77', '2.67', '0.47', '-1.39', '-0.28', '-1.79', '3.04', '0.96', '-2.81', '1.83', '-1.48', '-1.34', '-0.06', '-1.83', '0.50', '0.37', '-0.95', '-1.31', '-1.15', '2.11']\n",
            "True: tensor(0)  - predicted: tensor(0) ['2.77', '0.07', '-0.25', '-0.77', '-1.72', '1.44', '0.18', '-0.53', '-0.14', '0.10', '-0.10', '0.39', '0.84', '-1.01', '-1.02', '0.26', '-0.62', '-0.09', '-0.10', '0.96']\n",
            "True: tensor(8)  - predicted: tensor(8) ['-1.34', '-0.86', '-0.96', '0.90', '-0.93', '-2.71', '-0.98', '0.04', '2.52', '0.28', '1.61', '-0.48', '-0.93', '1.70', '0.23', '0.10', '-0.48', '2.32', '0.41', '-0.29']\n",
            "True: tensor(15)  - predicted: tensor(15) ['-0.77', '-1.05', '-0.30', '0.20', '0.30', '-0.35', '0.01', '0.61', '-0.22', '0.56', '-0.17', '0.22', '-0.18', '-0.08', '-1.35', '1.00', '0.99', '0.44', '0.12', '0.07']\n",
            "True: tensor(10)  - predicted: tensor(10) ['1.27', '-0.20', '0.20', '1.36', '-0.95', '-0.02', '-1.29', '0.06', '-0.48', '-0.16', '2.00', '-0.73', '-0.31', '-0.04', '-0.45', '-0.30', '-0.47', '0.90', '0.25', '-0.57']\n",
            "True: tensor(17)  - predicted: tensor(17) ['-0.75', '-2.01', '-0.64', '1.58', '0.52', '-0.85', '-1.60', '-0.43', '0.01', '0.57', '1.79', '-1.03', '-0.66', '0.69', '-1.62', '0.63', '0.15', '3.07', '0.63', '-0.77']\n",
            "True: tensor(9)  - predicted: tensor(9) ['-0.93', '0.92', '-0.42', '0.01', '-2.10', '-0.33', '0.66', '-1.20', '-0.15', '2.69', '0.23', '-0.71', '0.79', '-0.61', '0.29', '-0.37', '-1.15', '0.58', '-1.16', '0.93']\n",
            "True: tensor(19)  - predicted: tensor(6) ['-0.30', '1.53', '-0.20', '-0.94', '-0.11', '-0.19', '2.42', '-1.84', '-0.91', '0.39', '-0.01', '-0.47', '0.65', '-1.20', '0.14', '0.15', '-0.59', '-0.33', '0.14', '1.68']\n",
            "True: tensor(5)  - predicted: tensor(14) ['0.41', '-0.54', '-0.00', '-1.82', '-0.57', '0.89', '-0.00', '1.06', '-0.90', '1.07', '-1.79', '0.92', '0.85', '-1.04', '1.47', '-0.17', '-0.13', '-0.44', '-0.23', '0.26']\n",
            "True: tensor(17)  - predicted: tensor(17) ['-0.97', '-1.60', '-0.97', '1.49', '-0.71', '-0.01', '-1.37', '-0.40', '1.58', '-0.16', '2.55', '-0.99', '-1.18', '1.50', '-1.13', '0.60', '-0.60', '2.86', '1.11', '-1.55']\n",
            "True: tensor(0)  - predicted: tensor(0) ['4.23', '0.80', '0.29', '-1.44', '-0.23', '0.91', '-0.52', '-0.02', '-1.38', '-0.50', '-1.68', '0.43', '0.34', '-1.53', '0.74', '-1.12', '1.02', '-0.70', '-0.88', '0.67']\n",
            "True: tensor(8)  - predicted: tensor(13) ['-0.43', '-1.07', '-0.63', '1.00', '-0.50', '-0.78', '-2.56', '1.28', '0.81', '-0.23', '0.26', '-0.10', '-0.85', '2.12', '-0.11', '0.18', '-0.07', '1.32', '-0.16', '-1.89']\n",
            "True: tensor(19)  - predicted: tensor(19) ['-0.58', '1.43', '0.50', '-1.16', '0.12', '-0.31', '1.01', '0.33', '-1.17', '1.33', '-0.32', '0.06', '-0.39', '-1.26', '0.91', '-0.63', '-0.71', '-0.21', '-0.70', '1.92']\n",
            "True: tensor(13)  - predicted: tensor(13) ['-0.97', '-2.22', '-0.56', '1.27', '0.64', '-0.71', '-0.97', '-0.77', '0.71', '-0.96', '1.65', '0.07', '-0.27', '2.01', '-0.67', '-0.19', '0.18', '0.78', '1.64', '-1.02']\n",
            "True: tensor(4)  - predicted: tensor(4) ['-0.88', '-1.74', '2.29', '0.49', '2.31', '-0.22', '-0.05', '0.05', '-1.84', '-0.10', '0.17', '0.60', '-0.27', '-0.55', '-1.39', '0.28', '1.55', '-1.09', '0.73', '0.07']\n",
            "True: tensor(14)  - predicted: tensor(14) ['0.02', '0.50', '-1.88', '-0.42', '-1.06', '0.32', '-0.34', '1.11', '-0.27', '0.57', '-0.14', '-0.44', '0.30', '0.04', '3.31', '-0.76', '-1.42', '1.33', '-0.77', '0.29']\n",
            "True: tensor(12)  - predicted: tensor(12) ['-0.34', '-0.60', '-0.09', '0.19', '-1.13', '0.58', '-1.97', '1.09', '-1.03', '-0.32', '-0.03', '1.08', '2.04', '-0.44', '-1.09', '0.25', '0.09', '-0.55', '0.46', '-0.24']\n",
            "True: tensor(8)  - predicted: tensor(8) ['0.42', '-1.04', '-0.78', '0.63', '-0.22', '-0.96', '-1.17', '-0.58', '2.59', '-0.25', '1.71', '-0.74', '-0.36', '1.02', '-1.03', '0.91', '0.77', '0.94', '0.04', '-1.29']\n",
            "True: tensor(18)  - predicted: tensor(18) ['-0.46', '-1.14', '-0.20', '0.52', '-0.03', '-1.03', '-0.65', '0.85', '-0.62', '-0.30', '0.70', '1.06', '0.86', '0.61', '0.01', '-0.23', '-0.17', '-0.20', '2.64', '-0.08']\n",
            "True: tensor(2)  - predicted: tensor(2) ['-0.12', '-1.09', '2.18', '-0.28', '0.74', '0.61', '-0.98', '0.63', '-1.42', '-1.28', '-0.97', '1.70', '0.41', '-0.83', '-0.91', '1.08', '1.84', '-0.71', '0.05', '-0.29']\n",
            "True: tensor(3)  - predicted: tensor(3) ['-1.26', '-1.11', '-0.39', '2.49', '0.48', '-1.22', '-0.84', '-0.83', '0.57', '-0.07', '0.92', '0.94', '-0.47', '1.22', '-1.42', '0.45', '-0.63', '-0.19', '1.25', '0.37']\n",
            "True: tensor(6)  - predicted: tensor(6) ['0.08', '-0.46', '0.24', '-0.87', '-0.11', '0.28', '1.10', '-0.12', '-0.93', '0.51', '-0.62', '-0.18', '-0.68', '-1.27', '0.49', '0.55', '0.28', '-0.34', '-0.10', '0.55']\n",
            "True: tensor(2)  - predicted: tensor(5) ['0.50', '-2.43', '1.79', '-0.96', '1.95', '2.31', '-0.70', '-0.05', '-1.74', '-0.99', '-0.80', '0.62', '0.23', '-1.06', '-1.55', '1.57', '2.07', '-0.23', '0.71', '-0.80']\n",
            "True: tensor(15)  - predicted: tensor(2) ['-1.19', '0.24', '0.72', '0.24', '0.39', '-0.35', '-0.18', '0.39', '-1.91', '0.71', '-0.67', '0.23', '0.03', '-0.41', '-1.07', '0.30', '0.33', '-0.12', '0.26', '0.47']\n",
            "True: tensor(14)  - predicted: tensor(14) ['0.27', '1.20', '-0.66', '-0.60', '-0.99', '-0.35', '2.06', '-1.78', '-0.55', '0.50', '-0.31', '-0.80', '-0.25', '-0.97', '2.36', '-1.17', '-1.34', '-1.22', '0.57', '1.78']\n",
            "True: tensor(12)  - predicted: tensor(12) ['1.26', '-0.79', '0.32', '-0.66', '-1.34', '2.25', '-0.82', '-0.52', '-1.57', '1.59', '-0.47', '0.97', '2.28', '-1.14', '-1.46', '-0.11', '0.41', '-0.45', '-0.01', '0.10']\n",
            "True: tensor(19)  - predicted: tensor(12) ['-0.35', '0.20', '-0.86', '-0.26', '-0.52', '0.74', '0.53', '0.23', '-1.46', '-0.15', '-0.79', '0.40', '0.98', '-1.21', '0.98', '0.44', '-0.22', '-0.72', '0.02', '0.91']\n",
            "True: tensor(3)  - predicted: tensor(3) ['-1.29', '-1.40', '0.10', '1.99', '-0.49', '-0.82', '-2.60', '-0.78', '1.41', '-0.57', '1.85', '-0.04', '-1.32', '1.83', '-0.26', '-0.06', '0.25', '0.75', '0.81', '-1.23']\n",
            "True: tensor(18)  - predicted: tensor(18) ['-1.17', '-2.11', '-0.05', '0.87', '0.86', '0.12', '-0.51', '0.04', '-0.48', '-0.25', '0.31', '0.90', '0.12', '0.47', '-0.87', '0.14', '0.14', '-0.47', '2.06', '-1.22']\n",
            "True: tensor(7)  - predicted: tensor(7) ['-1.62', '-0.42', '0.55', '0.74', '-0.03', '-0.17', '-1.49', '1.95', '-1.02', '0.05', '-0.66', '0.54', '-0.62', '-0.61', '-1.23', '1.64', '0.80', '-0.03', '0.82', '-0.40']\n",
            "True: tensor(1)  - predicted: tensor(1) ['-0.11', '2.61', '-0.17', '-1.21', '-1.13', '-1.14', '1.79', '-0.57', '-0.97', '0.43', '-0.57', '0.26', '0.71', '-1.17', '0.79', '-0.22', '-0.52', '-0.80', '-0.54', '2.44']\n",
            "True: tensor(5)  - predicted: tensor(5) ['1.70', '-2.13', '-0.14', '-0.59', '-0.31', '2.00', '-1.77', '-0.06', '-1.20', '0.17', '0.02', '-0.52', '1.56', '-0.36', '-0.09', '-0.04', '0.71', '-0.11', '0.74', '-1.06']\n",
            "True: tensor(9)  - predicted: tensor(9) ['0.49', '0.34', '0.69', '-0.19', '-0.47', '-0.66', '0.17', '-0.17', '-0.68', '1.23', '-0.40', '-0.36', '0.55', '-0.37', '-0.18', '0.13', '0.27', '-0.89', '-0.66', '0.07']\n",
            "True: tensor(1)  - predicted: tensor(1) ['-1.35', '3.02', '0.70', '-0.52', '-1.46', '-0.69', '1.79', '0.01', '-0.93', '0.87', '-1.26', '-0.05', '-0.41', '-1.16', '0.23', '-0.69', '0.01', '-0.64', '-0.57', '1.91']\n",
            "True: tensor(7)  - predicted: tensor(16) ['-1.91', '-1.55', '0.90', '0.67', '1.12', '-0.76', '-1.15', '1.91', '-0.67', '-0.40', '0.66', '0.15', '0.30', '0.55', '-2.06', '1.61', '2.34', '-0.18', '1.49', '-0.99']\n",
            "True: tensor(9)  - predicted: tensor(10) ['0.23', '-0.29', '-1.61', '0.49', '0.15', '-1.54', '0.12', '-0.87', '0.91', '0.34', '1.31', '-0.17', '0.01', '1.22', '1.11', '0.32', '-1.42', '-0.64', '0.73', '0.71']\n",
            "True: tensor(6)  - predicted: tensor(6) ['-0.53', '0.11', '0.65', '-0.66', '-0.34', '-0.34', '1.79', '-0.05', '-2.12', '1.45', '-0.85', '-1.07', '-0.45', '-1.16', '0.50', '0.20', '-0.65', '-0.94', '-0.51', '0.26']\n",
            "True: tensor(15)  - predicted: tensor(2) ['0.23', '-0.22', '1.59', '-0.63', '0.11', '0.37', '0.05', '0.70', '-1.72', '0.82', '-0.09', '-0.08', '-0.20', '-0.78', '-1.35', '1.30', '-0.20', '0.15', '-0.91', '-1.42']\n",
            "True: tensor(11)  - predicted: tensor(7) ['-0.66', '-1.54', '0.79', '0.49', '1.23', '-1.05', '-0.24', '1.47', '-0.25', '-0.87', '-0.11', '1.03', '-0.35', '1.14', '-1.44', '0.54', '0.68', '-0.13', '0.34', '-0.82']\n",
            "True: tensor(13)  - predicted: tensor(8) ['-0.30', '-1.09', '-1.11', '1.69', '-1.16', '-1.00', '-2.32', '-0.86', '2.69', '-0.99', '1.90', '-0.27', '-0.34', '1.58', '-0.24', '-0.70', '-0.42', '0.99', '0.71', '-0.81']\n",
            "True: tensor(11)  - predicted: tensor(17) ['-1.50', '-1.95', '-0.67', '1.42', '0.96', '-1.20', '-1.55', '0.22', '0.34', '0.10', '0.13', '0.20', '-0.80', '1.14', '-0.35', '0.13', '0.51', '1.97', '0.65', '-1.02']\n",
            "True: tensor(16)  - predicted: tensor(17) ['-0.15', '-0.32', '-0.51', '0.18', '-0.34', '-0.10', '-1.18', '0.17', '-1.02', '0.46', '-0.14', '-0.45', '0.86', '0.32', '0.22', '0.09', '0.46', '1.08', '-0.65', '0.04']\n",
            "True: tensor(16)  - predicted: tensor(16) ['-0.27', '-1.76', '2.09', '-0.30', '1.67', '1.17', '-0.94', '0.58', '-1.96', '-0.86', '-0.66', '0.67', '0.73', '-0.81', '-1.97', '1.22', '2.25', '-1.04', '0.79', '-1.54']\n",
            "True: tensor(14)  - predicted: tensor(14) ['1.31', '0.80', '-0.77', '0.26', '-1.62', '-0.31', '0.73', '-1.42', '-0.05', '-0.29', '-0.34', '-0.57', '-0.16', '-1.03', '3.81', '-0.83', '-1.37', '-0.62', '0.26', '1.27']\n",
            "True: tensor(12)  - predicted: tensor(7) ['0.12', '-0.70', '-0.78', '0.35', '-1.58', '-0.07', '-0.58', '1.28', '-1.13', '-0.71', '-0.25', '1.26', '1.09', '-0.57', '0.17', '-1.12', '0.14', '-0.64', '0.33', '1.13']\n",
            "True: tensor(10)  - predicted: tensor(10) ['0.08', '-0.77', '0.04', '-0.16', '0.42', '-0.33', '-0.30', '0.01', '-0.37', '0.60', '0.85', '-0.73', '0.20', '0.58', '-0.81', '-0.19', '0.01', '-0.18', '0.14', '0.06']\n",
            "True: tensor(6)  - predicted: tensor(6) ['1.55', '0.09', '0.07', '-0.91', '0.20', '-0.06', '1.80', '-0.92', '-1.44', '0.40', '-0.29', '-0.31', '0.45', '0.13', '-0.44', '-1.05', '-0.72', '-0.36', '0.07', '0.80']\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(torch.max(outputs, 1)[1])):\n",
        "    formatted_tensor = [f\"{val:.2f}\" for val in outputs[i].tolist()]\n",
        "    print('True:',labels[i], ' - predicted:', torch.max(outputs, 1)[1][i], formatted_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-2.7647, -2.0875,  1.8545,  0.9179,  1.0721,  0.0081, -1.9767,  0.1883,\n",
              "        -2.2914,  2.0137, -0.5033,  0.4946, -0.6050,  0.9940, -1.9738,  2.4961,\n",
              "         0.3647, -0.7823,  1.0296, -1.2975], grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs[0] + outputs[1]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
